{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT DATA: FILTERING, FLATTENING, AND CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing n-grams\n",
    "import pandas\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load reviews\n",
    "f = open('yelp_academic_data_set_review.json')\n",
    "js = []\n",
    "for i in range(10000):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "review_df = pd.DataFrame(js)\n",
    "\n",
    "# Create feature transformers for unigrams, bigrams, trigrams.\n",
    "# The default ignores single character words, which is useful in practice because\n",
    "# it trims uninformative words, but we include them here \n",
    "bow_convertor = CountVectorizer(token_pattern = '(?u)\\\\b\\\\w+\\\\b')\n",
    "bigram_convertor = CountVectorizer(ngram_range = (2,2), token_pattern = '(?u)\\\\b\\\\w+\\\\b')\n",
    "trigram_convertor = CountVectorizer(ngram_range = (3,3), token_pattern = '(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Fit the transformers and look at the vocab size\n",
    "bow_convertor.fit(review_df['text'])\n",
    "words = bow_convertor.get_feature_names()\n",
    "\n",
    "bigram_convertor.fit(review_df['text'])\n",
    "bigrams = bigram_convertor.get_feature_names()\n",
    "\n",
    "trigram_convertor.fit(review_df['text'])\n",
    "trigrams = trigram_convertor.get_feature_names()\n",
    "print(len(words), len(bigrams), len(trigrams))\n",
    "\n",
    "print(words[:10])\n",
    "print(bigrams[-10:])\n",
    "print(trigrams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering using Stemming\n",
    "# Stemming\n",
    "import nltk\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "print(stemmer.stem('flowers'))\n",
    "print(stemmer.stem('zeroes'))\n",
    "print(stemmer.stem('stemmer'))\n",
    "print(stemmer.stem('sixties'))\n",
    "print(stemmer.stem('sixty'))\n",
    "print(stemmer.stem('goes'))\n",
    "print(stemmer.stem('go'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging and chunking\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "f = open('yelp_academic_data_set_review.json')\n",
    "js = []\n",
    "for i in range(10):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "review_df = pd.DataFrame(js)\n",
    "\n",
    "# Using Spacy\n",
    "import spacy\n",
    "# preload the language model\n",
    "nlp = spacy.load('en')\n",
    "# Create pandas series of spaCy nlp vars\n",
    "doc_df = review_df['text'].apply(nlp)\n",
    "# spaCy gives us fine-grained parts of speech using pos and coarse-grained parts of speech using tag\n",
    "for doc in doc_df[4]:\n",
    "    print([doc.text, doc.pos_, doc.tag_])\n",
    "#spaCy also does some basic noun chunking...\n",
    "print([chunk for chunk in doc_df[4].noun_chunks])\n",
    "\n",
    "# Using TextBlob\n",
    "# The default tagger in TextBlob uses the Pattern Tagger, which is cool\n",
    "# NLTK Tagger can also be specified, which works better for incomplete sentences\n",
    "blob_df = review_df[text].apply(TextBlob)\n",
    "print(blob_df[4].tags)\n",
    "print([np for np in blob_df[4].noun_phrases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hypothesis Testing - 1](Images/Hypothesis_Tesing-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hypothesis Testing - 2](Images/Hypothesis_Tesing-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hypothesis Testing - 3](Images/Hypothesis_Tesing-3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hypothesis Testing - 4](Images/Hypothesis_Tesing-4.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
