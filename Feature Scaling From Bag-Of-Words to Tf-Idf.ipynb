{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Effects of Feature Scaling: From Bag-Of_Words to Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-Idf -> Term Frequency Inverse Document Frequency -> A Better Approach\n",
    "\n",
    "# 4-1\n",
    "# Loading and cleaning the Yelp reviews dataset in Python\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load data (business data)\n",
    "biz_f = open('yelp_academic_dataset_business.json')\n",
    "biz_df = pd.DataFrame([json.loads(x) for x in biz_f.readlines()])\n",
    "biz_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yelp reviews data\n",
    "review_file = open('yelp_academic_dataset_review.json')\n",
    "review_df = pd.DataFrame([json.loads(x) for x in review_file.readlines()])\n",
    "review_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out only Nightlife and Restaurants businesses\n",
    "two_biz = biz_df[biz_df.apply(lambda x: 'Nightlife' in x['categories'] or 'Restaurants' in x['categories'], axis = 1)]\n",
    "\n",
    "# Join with the reviews to get all reviews on the two types of business\n",
    "twobiz_reviews = two_biz.merge(review_df, on='business_id', how='inner')\n",
    "\n",
    "# Trim away the features we won't use\n",
    "twobiz_reviews = twobiz_reviews[['business_id', 'name', 'stars_y', 'text', 'categories']]\n",
    "\n",
    "# Create the target column--True for Nightlife businesses, and False otherwise\n",
    "two_biz.reviews['target'] = twobiz_reviews.apply(lambda x: 'Nightlife' in x['categories'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a balanced classification dataset\n",
    "# When datasets have categories and those are unbalanced categories, there is a need to balance the dataset equally...\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create a class-balanced subsample \n",
    "nightlife = twobiz_reviews[twobiz_reviews.apply(lambda x:'Nightlife' in x['categories'], axis=1)]\n",
    "restaurants = twobiz_reviews[twobiz_reviews.apply(lambda x:'Restaurants' in x['categories'], axis=1)]\n",
    "\n",
    "nightlife_subset = nightlife.sample(frac=0.1, random_state=123)\n",
    "restaurant_subset = restaurants.sample(frac=0.021, random_state=123)\n",
    "\n",
    "combined = pd.concat([nightlife_subset, restaurant_subset])\n",
    "\n",
    "# Split into training and test datasets\n",
    "training_data, test_data = train_test_split(combined, train_size = 0.7, random_state=123)\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Features\n",
    "\n",
    "# Represent the review text as a bag-of-words\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "bow_transform = text.CountVectorizer()\n",
    "\n",
    "X_tr_bow = bow_transform.fit_transform(training_data['text'])\n",
    "X_te_bow = bow_transform.transform(test_data['text'])\n",
    "\n",
    "print(len(bow_transform.vocabulary_))\n",
    "\n",
    "y_tr = training_data['target']\n",
    "y_te = test_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf-idf representation using the bag-of-words matrix\n",
    "tfidf_trfm = text.TfidfTransformer(norm=None)\n",
    "X_tr_tfidf = tfidf_trfm.fit_transform(X_tr_bow)\n",
    "X_te_tfidf = tfidf_trfm.transform(X_te_bow)\n",
    "\n",
    "# L2-Normalize the bag-of-words representation\n",
    "X_tr_l2 = preproc.normalize(X_tr_bow, axis=0)\n",
    "X_te_l2 = preproc.normalize(X_te_bow, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic regression classifiers with default params\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description):\n",
    "    m = LogisticRegression().fit(X_tr, y_tr)\n",
    "    s = m.score(X_test, y_test)\n",
    "    print('Test score with ', description, ' features: ', s)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling models\n",
    "m1 = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow')\n",
    "m2 = simple_logistic_classify(X_tr_l2, y_tr, X_te_l2, y_te, 'l2-normalized')\n",
    "m3 = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tf-idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results may show that BOw is the best but that's not true, because when the classifier is not tuned fine,\n",
    "# Then this becomes a pitfall at many times when taking the descision for the best classifier to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To tune the hyperparameters we use techniques such as resampling (k-fold cross validation) and,\n",
    "# regularization. These are some hyperparameters to tune the model.\n",
    "# Grid Search is generally used for hyperparameter tuning.\n",
    "\n",
    "# Tuning logistic regression hyperparameters with grid search\n",
    "import sklearn.model_selection as modsel\n",
    "# Specify a search grid, then do a 5-fold grid search for each of the feature sets\n",
    "param_grid_ = {'C':[1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2]}\n",
    "\n",
    "# Tune classifier for bag-of-words representation\n",
    "bow_search = modsel.GridSearchCV(LogisticRegression(), cv=5, param_grid = param_grid_)\n",
    "bow_search.fit(X_tr_bow, y_tr)\n",
    "\n",
    "# Tune classifier fir L2-normalized word vector\n",
    "l2_search = modsel.GridSearchCV(LogisticRegression(), cv=5, param_grid = param_grid_)\n",
    "l2_search.fit(X_tr_l2, y_tr)\n",
    "\n",
    "# Tune classifier for tf-idf\n",
    "tfidf_search = modsel.GridSearchCV(LogisticRegression(), cv=5, param_grid = param_grid_)\n",
    "tfidf_search.fit(X_tr_tfidf, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bow_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the cross validation results in a box-and-whiskers plot to visualize and compare classifier performance\n",
    "search_results = pd.DataFrame.from_dict({'bow': bow_search.cv_results_['mean_test_score'], 'tfidf': tfidf_search.cv_results_['mean_test_score'], 'l2': l2_search.cv_results_['mean_test_score']})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "ax = sns.boxplot(data = search_results, width=0.4)\n",
    "ax.set_ylabel('Accuracy', size=14)\n",
    "ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final training and testing step to compare the different feature sets\n",
    "# Train a final model on the entire training set, using the best hyperparameter\n",
    "# settings found prev. Measure accuracy on the test set...\n",
    "m1 = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow', _C = bow_search.best_params_['C'])\n",
    "m2 = simple_logistic_classify(X_tr_l2, y_tr, X_te_l2, y_te, 'l2-normalized', _C = l2_search.best_params_['C'])\n",
    "m3 = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tf-idf', _C = tfidf_search.best_params_['C'])\n",
    "\n",
    "# See the test accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
